{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f35b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def encode(a):\n",
    "    shifted = np.empty(a.size, dtype=np.int32)\n",
    "    shifted[:-1:] = a[1::]\n",
    "    shifted[-1]   = -100\n",
    "    print(shifted)\n",
    "    b = shifted != a\n",
    "    print(b)\n",
    "    \n",
    "    \n",
    "    return None\n",
    "\n",
    "x = np.array([1, 2, 2, 3, 3, 1, 1, 5, 5, 2, 3, 3])\n",
    "print(encode(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74899e0",
   "metadata": {},
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b8b1f4",
   "metadata": {},
   "source": [
    "# Избранное ДЗ <a name=\"hmwrk\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68412f1",
   "metadata": {},
   "source": [
    "0. Создать квадратную матрицу размера 8, на главной диаг. арифметическая прогрессия с шагом 3 (начиная с 3), а на побочной -1, остальные элементы 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab2a913",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = -1*np.eye(8)[::-1] + np.diag(np.arange(3, 27, 3))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24d28eb",
   "metadata": {},
   "source": [
    "1. Implementing matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee6a839",
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_numpy_mult(first, second):\n",
    "    \"\"\"\n",
    "    param first: list of \"size\" lists, each contains \"size\" floats\n",
    "    param second: list of \"size\" lists, each contains \"size\" floats\n",
    "    \"\"\"\n",
    "    sz = len(first)\n",
    "    return [ [sum( [first[i][k]*second[k][j] for k in range(sz)] ) for j in range(sz)] for i in range(sz) ]\n",
    "\n",
    "def numpy_mult(first, second):\n",
    "    \"\"\"\n",
    "    param first: np.array[size, size]\n",
    "    param second: np.array[size, size]\n",
    "    \"\"\"\n",
    "\n",
    "    return np.dot(first, second)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8394a1d",
   "metadata": {},
   "source": [
    "2. Implementing vector product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f5d240",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Way one:\n",
    "def no_numpy_scalar(v1, v2):\n",
    "    result = sum( [v1[k]*v2[k] for k in range(len(v1)) ] )\n",
    "    return result\n",
    "## Way two:\n",
    "def no_numpy_scalar(v1, v2):\n",
    "    result = sum( list(map(lambda x, y: x * y, v1, v2)) )\n",
    "    return result\n",
    "## Way three:\n",
    "def no_numpy_scalar(v1, v2):\n",
    "    result = sum( [x * y for x, y in zip(v1, v2)] )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8cc7e9",
   "metadata": {},
   "source": [
    "3. Сумма четных элементов на главной диагонали квадратной матрицы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291de91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One.\n",
    "def diag_2k(a):    \n",
    "    #param a: np.array[size, size]\n",
    "    diag = np.diagonal(a)\n",
    "    return np.sum( diag[diag % 2 == 0] )\n",
    "\n",
    "# Two.\n",
    "def diag_2k(a):    \n",
    "    #param a: np.array[size, size]\n",
    "    return np.trace( a * (a%2 == 0) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c341b888",
   "metadata": {},
   "source": [
    "4. Мегаслайсинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef3d7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Необходимо построить новый массив, где все элементы с нечетными индексами требуется заменить на число a (значение по умолчанию a=1). \n",
    "# Все элементы с четными индексами нужно возвести в куб. \n",
    "# Затем записать элементы в обратном порядке относительно их позиций. \n",
    "# В конце требуется слить массив xx с преобразованным xx и вернуть на выход функции \n",
    "# My solution:\n",
    "def transform(X, a=1):\n",
    "    \"\"\"\n",
    "    param X: np.array[batch_size, n]\n",
    "    \"\"\"\n",
    "\n",
    "    Y = np.empty( (X.shape[0], X.shape[1] * 2) , dtype=np.int64)\n",
    "    for i in range(X.shape[0]):\n",
    "        row = np.copy(X[i])\n",
    "        idx = np.indices(row.shape)\n",
    "        row[ idx[0] % 2 == 1 ] = a\n",
    "        row[ idx[0] % 2 == 0 ] = row[ idx[0] % 2 == 0 ] * row[ idx[0] % 2 == 0 ] * row[ idx[0] % 2 == 0 ]\n",
    "        Y[i] = np.concatenate( (X[i], row[::-1]) )\n",
    "\n",
    "    return Y\n",
    "# Better:\n",
    "def transform(X, a=1):\n",
    "    Y = np.copy(X)\n",
    "    Y[:, 1:2] = a\n",
    "    Y[:, 0:2] **= 3\n",
    "    return np.hstack(X, Y[:, ::-1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "52047496",
   "metadata": {},
   "source": [
    "# Numpy <a name=\"numpy\"></a> (Numerical Python)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a4246f41",
   "metadata": {},
   "source": [
    "**See https://numpy.org/doc/stable/user/absolute_beginners.html**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8f4efd58",
   "metadata": {},
   "source": [
    "## 1D Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcee9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "b = np.array( [1, 2, 3], dtype='int64' ) # Convert a python list to numpy.ndarray.\n",
    "print(type(b))\n",
    "c = np.array( [1, 2, 3] )  # int64 is already the default.\n",
    "print(type(c[0]))\n",
    "d = np.array( [1., 2, 3] ) # float64 is the default for float values.\n",
    "print(type(d[0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08bc6616",
   "metadata": {},
   "source": [
    "### Properties and Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d2486c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Help\n",
    "# np.lookfor('median') # ? * are also available.\n",
    "\n",
    "# Properties\n",
    "a = np.array([[[1, 2, 3, 4],\n",
    "                [2, 3, 4, 3],\n",
    "                [1, 1, 1, 1]], \n",
    "                [[1, 2, 3, 4],\n",
    "                [2, 3, 4, 3],\n",
    "                [1, 1, 1, 1]]])\n",
    "print(\"len:\", len(a), \"-- количество элементов по первой оси.\",\n",
    "      \"\\nsize:\", a.size, \"-- всего элементов в матрице.\",\n",
    "      \"\\nndim:\", a.ndim, \"-- размерность матрицы.\",\n",
    "      \"\\nshape:\", a.shape, \"-- количество элементов по каждой оси.\"\n",
    "      \"\\nnbytes:\", a.nbytes, \"-- размер матрицы в байтах.\",\n",
    "      \"\\ndtype:\", a.dtype, \"-- тип элементов матрицы.\")\n",
    "\n",
    "# Generating an array\n",
    "a = np.zeros(7, dtype='int64') # float64 here by default\n",
    "b = np.ones(7, dtype='int16')\n",
    "c = np.zeros_like(b)           # copies everything, dtype included\n",
    "print(c.dtype)\n",
    "\n",
    "# ARANGE - RETURN NDARRAY OF EVENLY SPACED VALUES WITHIN A GIVEN INTERVAL, FOCUS ON STEP\n",
    "a = np.arange(1, 16, 4) # [begin, end), step == range(1, 16, 4) here.\n",
    "# LINSPACE - RETURN NDARRAY OF EVENLY SPACED VALUES WITHIN A GIVEN INTERVAL, FOCUS ON POINTS\n",
    "a = np.linspace(1, 16, 10) # [begin, end], length\n",
    "b = np.logspace(0, 3, 12)  # evenly spaced on a base 10 log scale, from 10e0 to 10e3,\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "38529da1",
   "metadata": {},
   "source": [
    "**NB: Avoid using ndarrays in loops**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c5b9b18",
   "metadata": {},
   "source": [
    "## Operations on 1D-Arrays"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "02bdc6ef",
   "metadata": {},
   "source": [
    "### Element-wise operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dcb0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A + B, A - B, A / B, A * B\n",
    "a = np.linspace(1, 10, 10, dtype='int64')\n",
    "b = np.linspace(10, 20, 10, dtype='int64')\n",
    "\n",
    "# ALPHA * A\n",
    "a * 5, b + 10, a ** 2\n",
    "\n",
    "# IMPLICIT CASTS TO BIGGER ELEMENTS\n",
    "print(a + np.arange(10, dtype='int16'))\n",
    "print(type(a[0]))\n",
    "\n",
    "# UFUNCS - functions applied in element-wise fashion.\n",
    "np.cos(a)\n",
    "np.log(b)\n",
    "\n",
    "x = np.linspace(-4*np.pi, 4*np.pi, 100)\n",
    "np.all((np.sin(x)**2 + np.cos(x)**2).round() == 1)\n",
    "\n",
    "# LOGICAL\n",
    "print(a > b)\n",
    "print(a > 5)\n",
    "\n",
    "# ANY (E), ALL (V)\n",
    "a = np.arange(10., 20)\n",
    "print( np.any(a >= 10.), np.all(a > 15), sep=' ' )\n",
    "\n",
    "# INPLACE OPS\n",
    "a += np.sin(4) # *= /=, arrays also work\n",
    "\n",
    "# Constants\n",
    "print(np.e, np.pi)\n",
    "\n",
    "# CUMSUM - заменить на посл. частичных сумм\n",
    "b = np.arange(1, 21)\n",
    "print(f'{b}\\n{b.cumsum()}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c3c25fa9",
   "metadata": {},
   "source": [
    "**There are no exceptions on zero devision**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb309980",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array([0.0, 0.0, 1.0, -1.0]) / np.array([1.0, 0.0, 0.0, 0.0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e1c377d4",
   "metadata": {},
   "source": [
    "### Algos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2311b97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SORT\n",
    "a = np.array([1, 5, 6, 10, -2, 0, 18])\n",
    "print(np.sort(a), a) # np.SORT DOES NOT CHANGE ITS ARGUMENT.\n",
    "a.sort()             # SORT DOES.\n",
    "print(a)\n",
    "\n",
    "# JOIN\n",
    "b = np.linspace(1, 10, 20)\n",
    "print( np.hstack( (a, b) ) )\n",
    "# help(np.hstack) ## There are different ways of doing that."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0c710097",
   "metadata": {},
   "source": [
    "### Not element-wise operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152b4e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(1, 11) # The operations below do NOT change their argument (i.e. a).\n",
    "print( np.delete(a, [0, 5, 9] ) )  # Delete elements at idxs 0, 5, 9. You can also pass a tuple or an ndarray.\n",
    "print( np.insert(a, 2, [-100, +100]) ) # Insert [-100, +100] so that -100 has its idx = 2.\n",
    "print( np.append(a, [-0.1, +0.1, 0.0]) )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "da58c271",
   "metadata": {},
   "source": [
    "## Indexing and slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349927da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse an array.\n",
    "a = np.arange(1, 11)\n",
    "print(a[::-1])\n",
    "\n",
    "# Slicing merely makes a referece to a portion of an array.\n",
    "b = a[0:6]\n",
    "b[-1] = -10\n",
    "print(a) # Note that something like b = np.append(b, [-1, 1]) wouldn't change a.\n",
    "# To avoid that behaviour, use np.copy():\n",
    "b = np.copy(a)\n",
    "\n",
    "# Slicing with steps.\n",
    "print(a)\n",
    "b = a[0:6:2] # [begin, end), step\n",
    "print(b)\n",
    "\n",
    "# Indexing with an array of idxs.\n",
    "print(a[ [0, 7, -1] ])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8acae515",
   "metadata": {},
   "source": [
    "## 2D Arrays"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d88cf31d",
   "metadata": {},
   "source": [
    "### Specific operations <a name=\"specific_ops\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9ee787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making an array by hand.\n",
    "a = np.array( [\n",
    "    [1, 2],\n",
    "    [3, 4]\n",
    "] ) \n",
    "print(a, a.ndim)\n",
    "\n",
    "# Indexing ndim arrays\n",
    "print(a[1][1], a[1, 1])\n",
    "\n",
    "# Multiplication\n",
    "a = 5 * np.ones( (3, 3) )\n",
    "print(a)\n",
    "b = 3 * np.eye( 3 )\n",
    "print(a*b) # element-wise\n",
    "\n",
    "# Matrix multiplication\n",
    "print(a @ b)\n",
    "print(a.dot(b))\n",
    "print(np.dot(a, b))\n",
    "\n",
    "# Meshgrind does idk what"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "53ed1128",
   "metadata": {},
   "source": [
    "### Shaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce613fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping\n",
    "b = np.arange(0, 20)\n",
    "b.shape = [2, 10] # tuples also work\n",
    "print(b)\n",
    "print(b.ravel())  # Make it 1D, DOES NOT change its object.\n",
    "b = b.ravel()\n",
    "print(b.reshape(2, 10))       # Does the same thing as b.shape = ...\n",
    "print(np.reshape(b, (2, 10))) # Again\n",
    "\n",
    "# Generating, omiting the second number results in an 1D array of the specified length. \n",
    "a = np.ones( (2, 3) )\n",
    "b = np.zeros( (2, 3) )\n",
    "c = np.eye( 3 )\n",
    "d = np.diag( [1, 2, 3, 4] )\n",
    "print(a, b, c, d, sep='\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6cf521e7",
   "metadata": {},
   "source": [
    "### Masks & traces"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "11d807f7",
   "metadata": {},
   "source": [
    "Masks are boolean arrays indicating if an element of the same idx should be included in the result when the mask is applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ca8bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Masks.\n",
    "a = np.arange(20)\n",
    "print(a % 3 == 0) # That yields an array of bools, see operations on 1D arrays.\n",
    "print(a[ a % 3 == 0 ]) # Couple that with np.ones(..., dtype=bool) below.\n",
    "\n",
    "# Traces.\n",
    "b = np.diag( a[ a>=10 ] )\n",
    "print(b)\n",
    "print(np.trace(b))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d5e5a7dd",
   "metadata": {},
   "source": [
    "**NB: You can generate bool-type arrays using np.ones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc4aa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.ones((10, 10, 10), dtype=bool) # Notice how the second dim defaults to 1 here.\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a30383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cool problem:\n",
    "# Создать квадратную матрицу размера 8, на главной диаг. арифметическая прогрессия с шагом 3 (начиная с 3), \n",
    "# а на побочной -1, остальные элементы 0.\n",
    "a = -1*np.eye(8)[::-1] + np.diag(np.arange(3, 27, 3))\n",
    "print(a)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "04678262",
   "metadata": {},
   "source": [
    "## ND Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c8e49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.arange(64).reshape(8, 2, 4)\n",
    "print(A) # 8 layers -> 2 rows -> 4 columns\n",
    "print(A.shape, A.ndim, A.size, len(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d497209c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(A, axis=0)) # Sum of all layes, \"removes\" the first axis.\n",
    "!echo $((0 + 8 + 16 + 24 + 32 + 40 + 48 + 56)) \n",
    "print(np.sum(A, axis=1)) # Sum of rows within each layer, \"removes\" the second axis.\n",
    "print(np.sum(A, axis=2)) # Sum of cols within each layer.\n",
    "\n",
    "print(np.sum(A, axis=(1, 2))) # Sum of rows and cols right after. Each layer gets \"replaced\" with a sum.\n",
    "# For a fixed i sums all elements indexed as (i, *, *)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2cb696ea",
   "metadata": {},
   "source": [
    "## Linear Algebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8706b822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determinant.\n",
    "a = np.array( [ [1, 2], [2, 3] ] )\n",
    "print(np.linalg.det(a) )\n",
    "\n",
    "# Inverse.\n",
    "b = np.linalg.inv(a)\n",
    "print(a @ b, b @ a, sep='\\n')\n",
    "\n",
    "# If the matrix is singular:\n",
    "c = np.array([[2, 1], [6, 3]])\n",
    "print(c)\n",
    "print(np.linalg.det(c)) \n",
    "try:\n",
    "    np.linalg.inv(c)\n",
    "except:\n",
    "    print(\"Oops!\")\n",
    "\n",
    "# Solving a СЛАУ.\n",
    "# 2x + y  = 5     |  (2, 1) (x) = (5)\n",
    "# 2x + 3y = -10   |  (2, 3) (y) = (-10)\n",
    "b = np.array( [5, -10] )\n",
    "a = np.array([[2, 1], [2, 3]])\n",
    "print(np.linalg.solve(a, b))\n",
    "print(a @ np.linalg.solve(a, b))\n",
    "\n",
    "# СВ и СЗ\n",
    "vals, vecs = np.linalg.eig(a.T) # T!!!\n",
    "print(vals, vecs, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a199213",
   "metadata": {},
   "source": [
    "# Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d284dc",
   "metadata": {},
   "source": [
    "## pd.Series - a column of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fcf937",
   "metadata": {},
   "source": [
    "### Making a series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7292312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# SERIES CREATION\n",
    "ser = pd.Series( range(0,10) )         # Using an iterable.\n",
    "ser = pd.Series( np.array([1, 2, 3]) ) # Using an array-like object. Indexed as 0, 1, 2.\n",
    "ser = pd.Series( [ np.array([1, 2, 3]), np.array([-1, -2, -3]) ] ) # ser[0][0] yields 1.\n",
    "\n",
    "data = [1, 2, 3, np.nan, 6, 8]  # np.nan is a float value meaning a gap in data. \n",
    "ser  = pd.Series(data, index=['day one', 'day two', 'day 3', '4', '5', 'six'], name='Some random stuff')\n",
    "print(ser['day two'])\n",
    "print(ser); print()\n",
    "\n",
    "ser = pd.Series([1, 2, 3])\n",
    "print(ser[1]) # ser['1'] is an error.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d4eb09",
   "metadata": {},
   "source": [
    "### Indexing & slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c9a72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SLICING\n",
    "data = [1, 2, 3, np.nan, 6, 8]  # np.nan is a float value meaning a gap in data. \n",
    "ser  = pd.Series(data, name='Exemplary series')\n",
    "print(ser, '\\n----------------')\n",
    "print(ser[2:-1], '\\n----------------') # NB: you cannot use -1 as an idx (i.e. ser[-1]) since -1 is not a valid KEY.\n",
    "print(ser[5:3:-1]) # 3:5 yields nothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "996ca1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-01    0.581458\n",
      "2023-01-02    0.251808\n",
      "2023-01-03    0.548128\n",
      "2023-01-04    0.211399\n",
      "2023-01-05    0.732869\n",
      "2023-01-06    0.327858\n",
      "2023-01-07    0.452773\n",
      "2023-01-08    0.438470\n",
      "2023-01-09    0.809808\n",
      "2023-01-10    0.021223\n",
      "Freq: D, dtype: float64 \n",
      "-----------------------\n",
      "2023-01-01    0.581458\n",
      "2023-01-03    0.548128\n",
      "2023-01-05    0.732869\n",
      "2023-01-09    0.809808\n",
      "dtype: float64\n",
      "-----------------------\n",
      "2023-01-09    0.809808\n",
      "2023-01-10    0.021223\n",
      "Freq: D, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# CONDITIONAL INDEXING\n",
    "import numpy as np\n",
    "date_range = pd.date_range('20230101', periods=10)\n",
    "series     = pd.Series(np.random.rand(10), date_range) # implicitly index=date_range.\n",
    "print(series,'\\n-----------------------')\n",
    "\n",
    "print(series[ series > 0.5 ]) # series > 0.5 returns a series with the same indexes but True/False as corresponding values.\n",
    "# So yes, it is possible to use a series of bool values as a mask (index) for any another series of the same size.\n",
    "print('-----------------------')\n",
    "\n",
    "print(series[ (series > 0.8) | (series < 0.1) ]) # Using logical operators. & and ^ are also supported.\n",
    "series = (series == 'female').astype(int) # A way to sub binary string values (e.g. male and female) with 0 and 1 for easier data processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28eddaa2",
   "metadata": {},
   "source": [
    "### Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479bc1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "date_range = pd.date_range('20230101', periods=4)\n",
    "series     = pd.Series(np.random.rand(4), date_range) # implicitly index=date_range.\n",
    "print(series,'\\n-----------------------')\n",
    "\n",
    "# NB: none of sorts below CHANGE the series. Use = to change it.\n",
    "print(series[::-1].sort_index()) # Sorting by indexes, [::-1] so that it actually sorts :)\n",
    "print('-----------------------') \n",
    "print(series.sort_values())      # By values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be591a4e",
   "metadata": {},
   "source": [
    "### Operations on Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb594d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "date_range = pd.date_range('20230101', periods=6)\n",
    "series     = pd.Series(np.random.rand(6), date_range) # implicitly index=date_range.\n",
    "\n",
    "# Unary opsm, numpy ufuncs.\n",
    "series + 100 # *5, /2, etc\n",
    "series *= 10\n",
    "np.exp(series)\n",
    "np.cos(series)\n",
    "\n",
    "# Binary ops.\n",
    "date_range = pd.date_range('20230101', periods=4)\n",
    "series2 = pd.Series(np.random.rand(4), date_range) # low, high, quantity.\n",
    "#print(series, series2, sep='\\n')\n",
    "print(series + series2) # Indexes must be the same for this to work. Notice how you get NaNs.\n",
    "\n",
    "# Parameters.\n",
    "print(f'Size: {series.size}, shape: {series.shape}, ndim: {series.ndim}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d14e3fe",
   "metadata": {},
   "source": [
    "## pd.DataFrame - a table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c36307",
   "metadata": {},
   "source": [
    "### Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085c4836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From a dictionary\n",
    "dict = {'key_one': pd.Series( [1,2,3], index=['a', 'b', 'c'] ),\n",
    "        'key_two': pd.Series( [1.,2.,3.,4.], index=['a','b','c','d'] ),\n",
    "        'key_three': pd.Series( ['hey', 'wow'], index=[1, 2] )}\n",
    "# Column name = key, data = data_of_key\n",
    "df = pd.DataFrame(dict)\n",
    "print(df)\n",
    "print('---------------------')\n",
    "\n",
    "# From a list of lists\n",
    "import numpy as np\n",
    "array_like = [ [1, 3, 5], [7, 9, 11], [2, 4, 6], [np.nan, -1, 2.2] ] # The line below does the same in term of creating a df.\n",
    "#array_like = np.array( [ np.array([1,3,5]), np.array([7,9,11]), np.array([2,4,6]), np.array([np.nan, -1, 2.2]) ] )\n",
    "df = pd.DataFrame(array_like, index=['ling', 'yi', 'er', 'san'], columns=['zero', 'one', 'two'])\n",
    "print(df) # By default index and columns are simpy numbers from zero to whatever (illustrated by spelling them out in the example)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e303ff6b",
   "metadata": {},
   "source": [
    "### Getting all data, setting columns & idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c72942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "array_like = [ [1, 3, 5], [7, 9, 11], [2, 4, 6], [np.nan, -1, 2.2] ]\n",
    "df = pd.DataFrame(array_like, index=['ling', 'yi', 'er', 'san'], columns=['zero', 'one', 'two'])\n",
    "print(df, '\\n-----------------------')\n",
    "\n",
    "print(df.values) # Retuns a numpy.ndarray.\n",
    "print(df.columns) # Retuns a pandas.Index. (?)\n",
    "print(df.index)\n",
    "print('-------------------')\n",
    "df.columns = np.array(['col1', 'col2', 'col3']) # Yes, that works too. Though a simple list is much better here.\n",
    "df.index   = [1, 2, 3, 4]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f1bb73",
   "metadata": {},
   "source": [
    "### Indexing a df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705e30e1",
   "metadata": {},
   "source": [
    "**INDEXED AS [COLUMN][ROW]! NOT THE MATRIX WAY.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40304eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "array_like = [ [1, 3, 5], [7, 9, 11], [2, 4, 6], [np.nan, -1, 2.2] ]\n",
    "df = pd.DataFrame(array_like, index=['ling', 'yi', 'er', 'san'], columns=['zero', 'one', 'two'])\n",
    "print(df, '\\n-----------------------1')\n",
    "\n",
    "# COLUMN INDEXING\n",
    "\n",
    "print( df['zero'] ) # Returns a pandas.Series.\n",
    "# print(df.zero)    # Same thing. \n",
    "print( df['zero']['er'], '\\n-----------------------2')\n",
    "# print( df['ling']['two'] ) # Error!\n",
    "\n",
    "sub_df = df[ ['zero', 'two'] ][1:3] # Returns a DataFrame.\n",
    "print(sub_df, '\\n-----------------------3')\n",
    "sub_df = df[['zero']] # In case we want a DataFrame, not a Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3fd9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROW INDEXING\n",
    "print(df, '\\n-----------------------1')\n",
    "# You can slice, of course:\n",
    "print(df[:1], '\\n-----------------------2')\n",
    "print(df[1:4], '\\n-----------------------3') # [low, high)\n",
    "\n",
    "# Purely integer-based indexing for selection by position:\n",
    "print( df.iloc[1:3, 1] ) # Row, col. Slicing works on both. THE RIGHT EDGE IS NOT INCLUDED!\n",
    "print('-----------------------4')\n",
    "# Label-based indexing for selection by position:\n",
    "print( df.loc['yi':'er', ['zero', 'two']] ) # THE RIGHT EDGE IS INCLUDED!\n",
    "# Doing smth like 1:3 here result in an error since 1 and 3 are not KEYS.\n",
    "print('-----------------------5')\n",
    "print( df.loc['yi']) # Retuns a row as a Series.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b146661e",
   "metadata": {},
   "source": [
    "### Modifying a DataFrame & some ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d767b5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "array_like = [ [1, 3, 5], [7, 9, 11], [2, 4, 6], [np.nan, -1, 2.2] ]\n",
    "df = pd.DataFrame(array_like, index=['ling', 'yi', 'er', 'san'], columns=['zero', 'one', 'two'])\n",
    "print(df, '\\n-----------------------1')\n",
    "\n",
    "# Adding a col\n",
    "new_col = [100, 200, 300, 400]\n",
    "df['three'] = new_col\n",
    "print(df, '\\n-----------------------2')\n",
    "\n",
    "# Simple ops\n",
    "df['two'] *= 4\n",
    "df['zero'] = df['two'] * 2\n",
    "print(df, '\\n-----------------------3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3323cc",
   "metadata": {},
   "source": [
    "## An example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ead5d8",
   "metadata": {},
   "source": [
    "### Reading a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04807764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.00</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pclass                                      Name     Sex   Age  \\\n",
       "PassengerId                                                                   \n",
       "889               3  Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN   \n",
       "890               1                     Behr, Mr. Karl Howell    male  26.0   \n",
       "891               3                       Dooley, Mr. Patrick    male  32.0   \n",
       "\n",
       "             SibSp  Parch      Ticket   Fare Cabin Embarked  \n",
       "PassengerId                                                  \n",
       "889              1      2  W./C. 6607  23.45   NaN        S  \n",
       "890              0      0      111369  30.00  C148        C  \n",
       "891              0      0      370376   7.75   NaN        Q  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Reading a csv\n",
    "filename = 'titanic_data.csv'\n",
    "titanic_passengers = pd.read_csv(filename, index_col='PassengerId') # Otherwise indexing is gonna be automatic which is redundant here.\n",
    "\n",
    "# Displaying\n",
    "titanic_passengers.head(3) # Returns a DataFrame.\n",
    "titanic_passengers.tail(3) # NB: print() does not give pretty output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524ca522",
   "metadata": {},
   "source": [
    "### Obtaining general info about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f7d4ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (rows, cols): (891, 10) \n",
      "----------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 1 to 891\n",
      "Data columns (total 10 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Pclass    891 non-null    int64  \n",
      " 1   Name      891 non-null    object \n",
      " 2   Sex       891 non-null    object \n",
      " 3   Age       714 non-null    float64\n",
      " 4   SibSp     891 non-null    int64  \n",
      " 5   Parch     891 non-null    int64  \n",
      " 6   Ticket    891 non-null    object \n",
      " 7   Fare      891 non-null    float64\n",
      " 8   Cabin     204 non-null    object \n",
      " 9   Embarked  889 non-null    object \n",
      "dtypes: float64(2), int64(3), object(5)\n",
      "memory usage: 76.6+ KB\n",
      "None \n",
      "----------------------------------\n",
      "           Pclass         Age       SibSp       Parch        Fare\n",
      "count  891.000000  714.000000  891.000000  891.000000  891.000000\n",
      "mean     2.308642   29.699118    0.523008    0.381594   32.204208\n",
      "std      0.836071   14.526497    1.102743    0.806057   49.693429\n",
      "min      1.000000    0.420000    0.000000    0.000000    0.000000\n",
      "25%      2.000000   20.125000    0.000000    0.000000    7.910400\n",
      "50%      3.000000   28.000000    0.000000    0.000000   14.454200\n",
      "75%      3.000000   38.000000    1.000000    0.000000   31.000000\n",
      "max      3.000000   80.000000    8.000000    6.000000  512.329200\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape (rows, cols): {titanic_passengers.shape}', '\\n----------------------------------')\n",
    "print(titanic_passengers.info(), '\\n----------------------------------')\n",
    "print(titanic_passengers.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b62685e",
   "metadata": {},
   "source": [
    "### Operations on columns, grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d96786e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42 29.69911764705882 80.0\n",
      "------------------------1\n",
      "male      577\n",
      "female    314\n",
      "Name: Sex, dtype: int64\n",
      "------------------------2\n",
      "              Age     SibSp     Parch       Fare\n",
      "Pclass                                          \n",
      "1       38.233441  0.416667  0.356481  84.154687\n",
      "2       29.877630  0.402174  0.380435  20.662183\n",
      "3       25.140620  0.615071  0.393075  13.675550\n",
      "Pclass\n",
      "1    38.233441\n",
      "2    29.877630\n",
      "3    25.140620\n",
      "Name: Age, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18802/4231093660.py:10: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  print(gr.mean()) # Reutns a DataFrame.\n"
     ]
    }
   ],
   "source": [
    "# Remember that series support many numpy operations!\n",
    "print(titanic_passengers['Age'].min(), titanic_passengers['Age'].mean(), titanic_passengers['Age'].max())\n",
    "print('------------------------1')\n",
    "# Count how many times each unique value occurs in a column. \n",
    "# How many men and women were there?\n",
    "print(titanic_passengers['Sex'].value_counts()) # Returns a series, you can also call value_counts() on the df itself.\n",
    "print('------------------------2')\n",
    "# Grouping entries by some value. \n",
    "gr = titanic_passengers.groupby(['Pclass']) # Split the df into groups, you can do more than one.\n",
    "print(gr.mean()) # Reutns a DataFrame.\n",
    "print(gr['Age'].mean()) # Retuns a Series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447c71d2",
   "metadata": {},
   "source": [
    "### Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d884c46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Survived\n",
      "0         0\n",
      "1         1 \n",
      "-------------1\n",
      "   Survived\n",
      "1         0\n",
      "2         1 \n",
      "-------------2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "columns overlap but no suffix specified: Index(['Survived'], dtype='object')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39m# Messing with the DataFrame.\u001b[39;00m\n\u001b[1;32m     11\u001b[0m titanic_survivors \u001b[39m=\u001b[39m titanic_survivors\u001b[39m.\u001b[39msample(frac\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m# Return a sample df, frac=1 makes it return the whole df but mixed (no longer sorted).\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m titanic_passengers \u001b[39m=\u001b[39m titanic_passengers\u001b[39m.\u001b[39;49mjoin(titanic_survivors) \u001b[39m# Restart the kernel to see it work.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m titanic_passengers\u001b[39m.\u001b[39mhead(\u001b[39m5\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/frame.py:9979\u001b[0m, in \u001b[0;36mDataFrame.join\u001b[0;34m(self, other, on, how, lsuffix, rsuffix, sort, validate)\u001b[0m\n\u001b[1;32m   9816\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mjoin\u001b[39m(\n\u001b[1;32m   9817\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   9818\u001b[0m     other: DataFrame \u001b[39m|\u001b[39m Series \u001b[39m|\u001b[39m \u001b[39mlist\u001b[39m[DataFrame \u001b[39m|\u001b[39m Series],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9824\u001b[0m     validate: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   9825\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[1;32m   9826\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   9827\u001b[0m \u001b[39m    Join columns of another DataFrame.\u001b[39;00m\n\u001b[1;32m   9828\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9977\u001b[0m \u001b[39m    5  K1  A5   B1\u001b[39;00m\n\u001b[1;32m   9978\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 9979\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_join_compat(\n\u001b[1;32m   9980\u001b[0m         other,\n\u001b[1;32m   9981\u001b[0m         on\u001b[39m=\u001b[39;49mon,\n\u001b[1;32m   9982\u001b[0m         how\u001b[39m=\u001b[39;49mhow,\n\u001b[1;32m   9983\u001b[0m         lsuffix\u001b[39m=\u001b[39;49mlsuffix,\n\u001b[1;32m   9984\u001b[0m         rsuffix\u001b[39m=\u001b[39;49mrsuffix,\n\u001b[1;32m   9985\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m   9986\u001b[0m         validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[1;32m   9987\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/frame.py:10018\u001b[0m, in \u001b[0;36mDataFrame._join_compat\u001b[0;34m(self, other, on, how, lsuffix, rsuffix, sort, validate)\u001b[0m\n\u001b[1;32m  10008\u001b[0m     \u001b[39mif\u001b[39;00m how \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcross\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m  10009\u001b[0m         \u001b[39mreturn\u001b[39;00m merge(\n\u001b[1;32m  10010\u001b[0m             \u001b[39mself\u001b[39m,\n\u001b[1;32m  10011\u001b[0m             other,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10016\u001b[0m             validate\u001b[39m=\u001b[39mvalidate,\n\u001b[1;32m  10017\u001b[0m         )\n\u001b[0;32m> 10018\u001b[0m     \u001b[39mreturn\u001b[39;00m merge(\n\u001b[1;32m  10019\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m  10020\u001b[0m         other,\n\u001b[1;32m  10021\u001b[0m         left_on\u001b[39m=\u001b[39;49mon,\n\u001b[1;32m  10022\u001b[0m         how\u001b[39m=\u001b[39;49mhow,\n\u001b[1;32m  10023\u001b[0m         left_index\u001b[39m=\u001b[39;49mon \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m  10024\u001b[0m         right_index\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m  10025\u001b[0m         suffixes\u001b[39m=\u001b[39;49m(lsuffix, rsuffix),\n\u001b[1;32m  10026\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m  10027\u001b[0m         validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[1;32m  10028\u001b[0m     )\n\u001b[1;32m  10029\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m  10030\u001b[0m     \u001b[39mif\u001b[39;00m on \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/reshape/merge.py:124\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39m@Substitution\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mleft : DataFrame or named Series\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     94\u001b[0m \u001b[39m@Appender\u001b[39m(_merge_doc, indents\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     95\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m     validate: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    109\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[1;32m    110\u001b[0m     op \u001b[39m=\u001b[39m _MergeOperation(\n\u001b[1;32m    111\u001b[0m         left,\n\u001b[1;32m    112\u001b[0m         right,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    122\u001b[0m         validate\u001b[39m=\u001b[39mvalidate,\n\u001b[1;32m    123\u001b[0m     )\n\u001b[0;32m--> 124\u001b[0m     \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mget_result(copy\u001b[39m=\u001b[39;49mcopy)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/reshape/merge.py:775\u001b[0m, in \u001b[0;36m_MergeOperation.get_result\u001b[0;34m(self, copy)\u001b[0m\n\u001b[1;32m    771\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_indicator_pre_merge(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright)\n\u001b[1;32m    773\u001b[0m join_index, left_indexer, right_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_join_info()\n\u001b[0;32m--> 775\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reindex_and_concat(\n\u001b[1;32m    776\u001b[0m     join_index, left_indexer, right_indexer, copy\u001b[39m=\u001b[39;49mcopy\n\u001b[1;32m    777\u001b[0m )\n\u001b[1;32m    778\u001b[0m result \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_merge_type)\n\u001b[1;32m    780\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindicator:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/reshape/merge.py:729\u001b[0m, in \u001b[0;36m_MergeOperation._reindex_and_concat\u001b[0;34m(self, join_index, left_indexer, right_indexer, copy)\u001b[0m\n\u001b[1;32m    726\u001b[0m left \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft[:]\n\u001b[1;32m    727\u001b[0m right \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright[:]\n\u001b[0;32m--> 729\u001b[0m llabels, rlabels \u001b[39m=\u001b[39m _items_overlap_with_suffix(\n\u001b[1;32m    730\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mleft\u001b[39m.\u001b[39;49m_info_axis, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mright\u001b[39m.\u001b[39;49m_info_axis, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msuffixes\n\u001b[1;32m    731\u001b[0m )\n\u001b[1;32m    733\u001b[0m \u001b[39mif\u001b[39;00m left_indexer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    734\u001b[0m     \u001b[39m# Pinning the index here (and in the right code just below) is not\u001b[39;00m\n\u001b[1;32m    735\u001b[0m     \u001b[39m#  necessary, but makes the `.take` more performant if we have e.g.\u001b[39;00m\n\u001b[1;32m    736\u001b[0m     \u001b[39m#  a MultiIndex for left.index.\u001b[39;00m\n\u001b[1;32m    737\u001b[0m     lmgr \u001b[39m=\u001b[39m left\u001b[39m.\u001b[39m_mgr\u001b[39m.\u001b[39mreindex_indexer(\n\u001b[1;32m    738\u001b[0m         join_index,\n\u001b[1;32m    739\u001b[0m         left_indexer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    744\u001b[0m         use_na_proxy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    745\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/reshape/merge.py:2458\u001b[0m, in \u001b[0;36m_items_overlap_with_suffix\u001b[0;34m(left, right, suffixes)\u001b[0m\n\u001b[1;32m   2455\u001b[0m lsuffix, rsuffix \u001b[39m=\u001b[39m suffixes\n\u001b[1;32m   2457\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m lsuffix \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m rsuffix:\n\u001b[0;32m-> 2458\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcolumns overlap but no suffix specified: \u001b[39m\u001b[39m{\u001b[39;00mto_rename\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   2460\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrenamer\u001b[39m(x, suffix):\n\u001b[1;32m   2461\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2462\u001b[0m \u001b[39m    Rename the left and right indices.\u001b[39;00m\n\u001b[1;32m   2463\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2474\u001b[0m \u001b[39m    x : renamed column name\u001b[39;00m\n\u001b[1;32m   2475\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: columns overlap but no suffix specified: Index(['Survived'], dtype='object')"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "titanic_survivors = pd.read_csv('titanic_surv.csv')\n",
    "print(titanic_survivors.head(2), '\\n-------------1')\n",
    "\n",
    "# Merging DataFrames, here we are merging by index.\n",
    "titanic_survivors.index = np.arange(1, len(titanic_survivors) + 1) # So Indexes match.\n",
    "print(titanic_survivors.head(2), '\\n-------------2')\n",
    "\n",
    "# Messing with the DataFrame.\n",
    "titanic_survivors = titanic_survivors.sample(frac=1) # Return a sample df, frac=1 makes it return the whole df but mixed (no longer sorted).\n",
    "# Even if the indexes are not sorted (but match!) join() will work:\n",
    "titanic_passengers = titanic_passengers.join(titanic_survivors) # Restart the kernel to see it work.\n",
    "titanic_passengers.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f9b9cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342\n",
      "342\n"
     ]
    }
   ],
   "source": [
    "# How many people survived?\n",
    "print(titanic_passengers['Survived'].sum()) \n",
    "print(titanic_passengers['Survived'].value_counts()[1]) # NOT COUNT_VALUES!\n",
    "# ... there also was task 4. corr()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fd16c316",
   "metadata": {},
   "source": [
    "# Python"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fddeea45",
   "metadata": {},
   "source": [
    "## Libs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f3b73e33",
   "metadata": {},
   "source": [
    "### Glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8914c691",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "!ls\n",
    "g = glob.glob('*.ipynb') # Return a list of paths matching a pathname pattern.\n",
    "print(g)\n",
    "#help(glob)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f6bc6d8a",
   "metadata": {},
   "source": [
    "### Collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d4ebbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "d = defaultdict(float)\n",
    "print( d.get('key', 'NONE') ) # Return the second param if not found. None by default. \n",
    "print(d['key'])               # Init an element with key 'key' with the default value of float.\n",
    "d['just evoke']               # Regular dict breaks here.\n",
    "print(d.items())\n",
    "\n",
    "from collections import Counter \n",
    "\n",
    "counter = Counter() # == defaultdict(int)\n",
    "for word in dir(__builtin__):\n",
    "    for letter in word:\n",
    "        #counter[letter] += 1\n",
    "        counter.update(letter)\n",
    "print(counter)\n",
    "# help(Counter)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "16ac2b86",
   "metadata": {},
   "source": [
    "## ipynb"
   ]
  },
  {
   "cell_type": "raw",
   "id": "59acccbd",
   "metadata": {},
   "source": [
    "Shift + Tab - display help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c92000d",
   "metadata": {},
   "outputs": [],
   "source": [
    "?str \n",
    "?np.median\n",
    "# this is just a tldr of help(str)\n",
    "np.co?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b676d9bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!ls /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681377a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "arr = []\n",
    "n = 10**7\n",
    "for i in range(n):\n",
    "    arr.append(i*5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "83d92294",
   "metadata": {},
   "source": [
    "## Language features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ecff5089",
   "metadata": {},
   "source": [
    "### Map, reduce, filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18a0a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## MAP - Map values from an iter to something else ##\n",
    "a = [1, 2, 3]\n",
    "b = [3, 2, 1]\n",
    "a_sq_it      = map(lambda x: x*x, a) \n",
    "a_b_cross_it = map(lambda n, m: n * m, a, b)\n",
    "print( tuple(a_sq), ' ', set(a_b_cross) ) # list\n",
    "# help(map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86791e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## REDUCE - Apply a function of two arguments cumulatively to the items of a sequence\n",
    "##   or iterable, so as to reduce the iterable to a single value.\n",
    "from functools import reduce\n",
    "c = [1, 2, 3, 4, 5]\n",
    "c_cumsum = reduce(lambda x, y: x + y, c, -100)\n",
    "print(c_cumsum)\n",
    "# help(reduce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9947a52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## FILTER - Return an iterator yielding those items of iterable for which predicate(item) is true ##\n",
    "d = ['Hi', 'Oof', 'Wolf', 'Car', 'Yield', 'Yeet', 'Extemporaneous', 'Basic']\n",
    "len_it = filter(lambda s: len(s) > 3, d)\n",
    "print( tuple(len_it) )\n",
    "#help(filter)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "64ca9389",
   "metadata": {},
   "source": [
    "### dict (set is ez)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfb40d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DICT COMPREHENSION\n",
    "e = {x*x for x in range(2, 7)}     ## This is a SET\n",
    "e = {x*x: x for x in range(2, 7)} ## This is a DICT\n",
    "print(e.values(), e.keys(), e.items(), sep='\\n')\n",
    "# keys are x*x, values are x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca42eda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## BASIC SYNTAX\n",
    "d = dict(key='key', value=2) # I wonder why that doesn't work :)\n",
    "print(d.items())\n",
    "if d.get('key') != None:     # d['key'] throws an exception here.\n",
    "    print('key is present!')\n",
    "else:\n",
    "    print ('no key;(')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "58269256",
   "metadata": {},
   "source": [
    "### Getting help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8255acb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1ef59aa0",
   "metadata": {},
   "source": [
    "### Progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8167cc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import trange, tqdm \n",
    "# There is the ususal tqdm as well which is best suited for command line.\n",
    "from time import sleep\n",
    "\n",
    "# Simple progress bar\n",
    "cnt = 0\n",
    "for i in tqdm(range(1000)):\n",
    "    sleep(0.001)\n",
    "    cnt += 1\n",
    "    \n",
    "# Nested progress bars\n",
    "for i in trange(10, desc='1st loop'): # trange(num) == tqdm(range(num))\n",
    "    for j in trange(100, desc='Another description', leave=False):\n",
    "        sleep(0.01)\n",
    "        \n",
    "# https://pypi.org/project/tqdm/\n",
    "# help(tqdm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c0a9a9cf",
   "metadata": {},
   "source": [
    "### join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434cc78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sep = '<--->'\n",
    "print(sep.join(['a', 'b', 'c']))\n",
    "\n",
    "## Example homework code:\n",
    "# def process(sentences):\n",
    "#    return [' '.join(filter( lambda word: word.isalpha(), sen.split(' ') )) for sen in sentences]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
